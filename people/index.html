<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content=""> <meta name="msvalidate.01" content=""> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>people | Yu Rong (Ëç£Èí∞)</title> <meta name="author" content="Yu Rong (Ëç£Èí∞)"> <meta name="description" content="members of the lab or group"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo.png?4a54cc56266f0070a91931424cbccf93"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://yurong-roy.github.io/people/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Yu¬†</span>Rong (Ëç£Èí∞)</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Me</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Publications</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/publications-by-year">By year</a> <a class="dropdown-item" href="/publications-by-year">By topic</a> </div> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">Talks</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">people</h1> <p class="post-description">members of the lab or group</p> </header> <article> <div class="post"> <article> <hr> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"> <p>555 your office number</p> <p>123 your address street</p> <p>Your City, State 12345</p> </div> </div> <div class="clearfix"> <p>Hi! I am currently the head of Language And Science AI Lab (LASA) of <a href="https://damo.alibaba.com/" rel="external nofollow noopener" target="_blank">DAMO Academy of Alibaba Group</a>. I am generally interested in developing the novel and efficient models with various complex data structures, includeing graphs and sequences to tackle real-world challenges, particularly in the realm of Language and Science.</p> <p>Prior joining DAMO Academy, I served as a principal researcher at <a href="https://ai.tencent.com/" rel="external nofollow noopener" target="_blank">Tencent AI Lab</a> for seven years. I briefly served as a Postdoctoral Research Fellow at The Chinese University of Hong Kong. I received Ph.D degree at <a href="https://www.cuhk.edu.hk/" rel="external nofollow noopener" target="_blank">The Chinese University of Hong Kong</a> in 2016, under the supervision of Professor <a href="https://www1.se.cuhk.edu.hk/~hcheng/" rel="external nofollow noopener" target="_blank">Hong CHENG</a>. Before that I obtained my B.S. degree with honors from <a href="https://www.sysu.edu.cn/" rel="external nofollow noopener" target="_blank">Sun Yat-sen University</a>.</p> <font color="red"> <strong>JOB OPENINGS NOW!!</strong>: I am looking for highly motivated <a href="https://talent-holding.alibaba.com/campus/position-detail?lang=zh&amp;positionId=2041201" rel="external nofollow noopener" target="_blank">full-time positions</a> / <a href="https://talent-holding.alibaba.com/campus/position-detail?lang=zh&amp;positionId=2036809" rel="external nofollow noopener" target="_blank">research interns</a> on large language model and AI for Science. </font> <h2 class="publications"><a href="/news/" style="color: inherit;">üî• What's New </a></h2> <div class="news"> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">May, 2025</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> Tow papers are accepted by ICML 2025! </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Mar, 2025</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> Released a new multilingual language model <a href="https://babel-llm.github.io/babel-llm/" rel="external nofollow noopener" target="_blank">babel</a>, covering the top 25 languages by number of speakers, supports over 90% of the global population. </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Feb, 2025</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> I will serve as Area Chair for KDD 2025. </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Jan, 2025</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> Four papers are accepted by ICLR 2025! <a href="https://openreview.net/forum?id=xJDxVDG3x2" rel="external nofollow noopener" target="_blank"> MolSpectra</a>, <a href="https://openreview.net/forum?id=nYPuSzGE3X" rel="external nofollow noopener" target="_blank">InversionGNN</a>,<a href="https://openreview.net/forum?id=mun3bGqdDM" rel="external nofollow noopener" target="_blank">Atomas</a> and <a href="https://openreview.net/forum?id=YslOW2SO6S" rel="external nofollow noopener" target="_blank">CirT</a>. </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Nov, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> One paper is accepted by ICDE 2025! </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Nov, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> One paper about sustainable battery recycling is published by Nature Communications! Check out this <a href="https://www.nature.com/articles/s41467-024-54454-0" rel="external nofollow noopener" target="_blank">Link</a> </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Nov, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> One paper for the protein desgin is accepted by KDD 2025! Check out our project page: <a href="https://ychaohao.github.io/PAAG/" rel="external nofollow noopener" target="_blank">PAAG</a> </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Aug, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> The campus recruitment of Damo Academy has started, offering <a href="https://talent-holding.alibaba.com/campus/position-list?campusType=freshman&amp;lang=zh" rel="external nofollow noopener" target="_blank">four positions</a> related to AI4Sci. </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Aug, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> I will serve as Area Chair for ICLR 2025. </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Jul, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> Two papers are accepted by CIKM 2024! Check out this <a href="https://dl.acm.org/doi/abs/10.1145/3627673.3679547" rel="external nofollow noopener" target="_blank">GLDM</a> and <a href="https://dl.acm.org/doi/abs/10.1145/3627673.3679529" rel="external nofollow noopener" target="_blank">NLA-MMR</a> </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Jul, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> Move to Hangzhou and join the DAMO Academy, Alibaba Group. </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">May, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> One paper is accepted by KDD 2024! </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">May, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> One paper is accepted by VLDB 2024! </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Mar, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> Our paper <a href="https://www.nature.com/articles/s41592-024-02214-9" rel="external nofollow noopener" target="_blank">scPROTEIN</a> are accepted by Nature Methods! </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Mar, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> A Survey of Geometric Graph Neural Networks is online now! <a href="https://arxiv.org/abs/2403.00485" rel="external nofollow noopener" target="_blank">link</a> </td> </tr> </table> </div> </div> </div> <h2 class="publications">üîç Current Research Topics</h2> <ul> <li>Deep Graph Learning <ul> <li>Foundations of Graph Neural Network</li> </ul> </li> <li>Large Language Models</li> <li>AI for Science <ul> <li>AI for Drug Discovery</li> <li>Physical Dynamic Simulation</li> </ul> </li> </ul> <h2 id="-recent-publications">üìù Recent Publications</h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">KDD</abbr> </div> <div id="10.1145/3637528.3671957" class="col-sm-9"> <div class="title">Relaxing Continuous Constraints of Equivariant Graph Neural Networks for Broad Physical Dynamics Learning</div> <div class="author"> Zinan Zheng,¬†Yang Liu,¬†Jia Li,¬†Jianhua Yao,¬†and¬†<em>Yu Rong</em> </div> <div class="periodical"> <em>In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Relaxing%20Continuous%20Constraints%20of%20Equivariant%20Graph%20Neural%20Networks%20for%20Broad%20Physical%20Dynamics%20Learning.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/compasszzn/DEGNN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Incorporating Euclidean symmetries (e.g. rotation equivariance) as inductive biases into graph neural networks has improved their generalization ability and data efficiency in unbounded physical dynamics modeling. However, in various scientific and engineering applications, the symmetries of dynamics are frequently discrete due to the boundary conditions. Thus, existing GNNs either over-look necessary symmetry, resulting in suboptimal representation ability, or impose excessive equivariance, which fails to generalize to unobserved symmetric dynamics. In this work, we propose a general Discrete Equivariant Graph Neural Network (DEGNN) that guarantees equivariance to a given discrete point group. Specifically, we show that such discrete equivariant message passing could be constructed by transforming geometric features into permutation-invariant embeddings. Through relaxing continuous equivariant constraints, DEGNN can employ more geometric feature combinations to approximate unobserved physical object interaction functions. Two implementation approaches of DEGNN are proposed based on ranking or pooling permutation-invariant functions. We apply DEGNN to various physical dynamics, ranging from particle, molecular, crowd to vehicle dynamics. In twenty scenarios, DEGNN significantly outperforms existing state-of-the-art approaches. Moreover, we show that DEGNN is data efficient, learning with less data, and can generalize across scenarios such as unobserved orientation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3637528.3671957</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Relaxing Continuous Constraints of Equivariant Graph Neural Networks for Broad Physical Dynamics Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zheng, Zinan and Liu, Yang and Li, Jia and Yao, Jianhua and Rong, Yu}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Barcelona, Spain}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{KDD '24}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4548‚Äì4558}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3637528.3671957}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400704901}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3637528.3671957}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{equivariant graph neural network, physical dynamics}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> </div> <div id="liu2024segno" class="col-sm-9"> <div class="title">SEGNO: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases</div> <div class="author"> Yang Liu,¬†Jiashun Cheng,¬†Haihong Zhao,¬†Tingyang Xu,¬†Peilin Zhao,¬†Fugee Tsung, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jia Li, Yu Rong' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">2 more authors</span> </div> <div class="periodical"> <em>In The Twelfth International Conference on Learning Representations</em>, 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/pdf?id=3oTPsORaDH" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/yliukj/SEGNO" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">liu2024segno</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{SEGNO}: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Yang and Cheng, Jiashun and Zhao, Haihong and Xu, Tingyang and Zhao, Peilin and Tsung, Fugee and Li, Jia and Rong, Yu}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The Twelfth International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=3oTPsORaDH}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">VLDB</abbr> </div> <div id="10.14778/3675034.3675048" class="col-sm-9"> <div class="title">Inductive Attributed Community Search: To Learn Communities Across Graphs</div> <div class="author"> Shuheng Fang,¬†Kangfei Zhao,¬†<em>Yu Rong</em>,¬†Zhixun Li,¬†and¬†Jeffrey Xu Yu</div> <div class="periodical"> <em>Proc. VLDB Endow.</em>, Aug 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/FangShuheng/IACS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/slides/VLDB24-IACS.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Attributed community search (ACS) aims to identify subgraphs satisfying both structure cohesiveness and attribute homogeneity in attributed graphs, for a given query that contains query nodes and query attributes. Previously, algorithmic approaches deal with ACS in a two-stage paradigm, which suffer from structural inflexibility and attribute irrelevance. To overcome this problem, recently, learning-based approaches have been proposed to learn both structures and attributes simultaneously as a one-stage paradigm. However, these approaches train a transductive model which assumes the graph to infer unseen queries is as same as the graph used for training. That limits the generalization and adaptation of these approaches to different heterogeneous graphs.In this paper, we propose a new framework, Inductive Attributed Community Search, IACS, by inductive learning, which can be used to infer new queries for different communities/graphs. Specifically, IACS employs an encoder-decoder neural architecture to handle an ACS task at a time, where a task consists of a graph with only a few queries and corresponding ground-truth. We design a three-phase workflow, "training-adaptation-inference", which learns a shared model to absorb and induce prior effective common knowledge about ACS across different tasks. And the shared model can swiftly adapt to a new task with small number of ground-truth. We conduct substantial experiments in 7 real-world datasets to verify the effectiveness of IACS for CS/ACS. Our approach IACS achieves 28.97% and 25.60% improvements in F1-score on average in CS and ACS, respectively.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.14778/3675034.3675048</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Inductive Attributed Community Search: To Learn Communities Across Graphs}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fang, Shuheng and Zhao, Kangfei and Rong, Yu and Li, Zhixun and Yu, Jeffrey Xu}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proc. VLDB Endow.}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{VLDB Endowment}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2576‚Äì2589}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.14778/3675034.3675048}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2150-8097}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.14778/3675034.3675048}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{June 2024}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> </div> <div id="li2024neural" class="col-sm-9"> <div class="title">Neural Atoms: Propagating Long-range Interaction in Molecular Graphs through Efficient Communication Channel</div> <div class="author"> Xuan Li,¬†Zhanke Zhou,¬†Jiangchao Yao,¬†<em>Yu Rong</em>,¬†Lu Zhang,¬†and¬†Bo Han</div> <div class="periodical"> <em>In The Twelfth International Conference on Learning Representations</em>, 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/pdf?id=CUfSCwcgqm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/tmlr-group/NeuralAtom" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2024neural</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neural Atoms: Propagating Long-range Interaction in Molecular Graphs through Efficient Communication Channel}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Xuan and Zhou, Zhanke and Yao, Jiangchao and Rong, Yu and Zhang, Lu and Han, Bo}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The Twelfth International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=CUfSCwcgqm}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">Nature Methods</abbr> </div> <div id="Li2024" class="col-sm-9"> <div class="title">scPROTEIN: a versatile deep graph contrastive learning framework for single-cell proteomics embedding</div> <div class="author"> Wei Li,¬†Fan Yang,¬†Fang Wang,¬†<em>Yu Rong</em>,¬†Linjing Liu,¬†Bingzhe Wu, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Han Zhang, Jianhua Yao' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">2 more authors</span> </div> <div class="periodical"> <em>Nature Methods</em>, Apr 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/TencentAILabHealthcare/scPROTEIN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/slides/NM-scPROTEIN_pub.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Single-cell proteomics sequencing technology sheds light on protein‚Äìprotein interactions, posttranslational modifications and proteoform dynamics in the cell. However, the uncertainty estimation for peptide quantification, data missingness, batch effects and high noise hinder the analysis of single-cell proteomic data. It is important to solve this set of tangled problems together, but the existing methods tailored for single-cell transcriptomes cannot fully address this task. Here we propose a versatile framework designed for single-cell proteomics data analysis called scPROTEIN, which consists of peptide uncertainty estimation based on a multitask heteroscedastic regression model and cell embedding generation based on graph contrastive learning. scPROTEIN can estimate the uncertainty of peptide quantification, denoise protein data, remove batch effects and encode single-cell proteomic-specific embeddings in a unified framework. We demonstrate that scPROTEIN is efficient for cell clustering, batch correction, cell type annotation, clinical analysis and spatially resolved proteomic data exploration.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Li2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{scPROTEIN: a versatile deep graph contrastive learning framework for single-cell proteomics embedding}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Wei and Yang, Fan and Wang, Fang and Rong, Yu and Liu, Linjing and Wu, Bingzhe and Zhang, Han and Yao, Jianhua}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">day</span> <span class="p">=</span> <span class="s">{01}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Nature Methods}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{21}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{623--634}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1038/s41592-024-02214-9}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1548-7105}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1038/s41592-024-02214-9}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">CIKM</abbr> </div> <div id="DBLP:conf/cikm/TanRZBXH0M24" class="col-sm-9"> <div class="title">Natural Language-Assisted Multi-modal Medication Recommendation</div> <div class="author"> Jie Tan,¬†<em>Yu Rong</em>,¬†Kangfei Zhao,¬†Tian Bian,¬†Tingyang Xu,¬†Junzhou Huang, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Hong Cheng, Helen Meng' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management, CIKM 2024, Boise, ID, USA, October 21-25, 2024</em>, 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://nlammr.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2501.07166v1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/jtan1102/NLA-MMR_CIKM_2024" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Combinatorial medication recommendation (CMR) is a fundamental task of healthcare, which offers opportunities for clinical physicians to provide more precise prescriptions for patients with intricate health conditions, particularly in the scenarios of long-term medical care. Previous research efforts have sought to extract meaningful information from electronic health records (EHRs) to facilitate combinatorial medication recommendations. Existing learning-based approaches further consider the chemical structures of medications, but ignore the textual medication descriptions in which the functionalities are clearly described. Furthermore, the textual knowledge derived from the EHRs of patients remains largely underutilized. To address these issues, we introduce the Natural Language-Assisted Multi-modal Medication Recommendation (NLAMMR), a multi-modal alignment framework designed to learn knowledge from the patient view and medication view jointly. Specifically, NLAMMR formulates CMR as an alignment problem from patient and medication modalities. In this vein, we employ pretrained language models (PLMs) to extract in-domain knowledge regarding patients and medications, serving as the foundational representation for both modalities. In the medication modality, we exploit both chemical structures and textual descriptions to create medication representations. In the patient modality, we generate the patient representations based on textual descriptions of diagnosis, procedure, and symptom. Extensive experiments conducted on three publicly accessible datasets demonstrate that NLAMMR achieves new state-of-the-art performance, with a notable average improvement of 4.72% in Jaccard score.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/cikm/TanRZBXH0M24</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tan, Jie and Rong, Yu and Zhao, Kangfei and Bian, Tian and Xu, Tingyang and Huang, Junzhou and Cheng, Hong and Meng, Helen}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Serra, Edoardo and Spezzano, Francesca}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Natural Language-Assisted Multi-modal Medication Recommendation}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 33rd {ACM} International Conference on Information
                          and Knowledge Management, {CIKM} 2024, Boise, ID, USA, October 21-25,
                          2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2200--2209}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{ACM}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3627673.3679529}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3627673.3679529}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Sat, 30 Nov 2024 21:10:26 +0100}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/conf/cikm/TanRZBXH0M24.bib}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">Nature Comm.</abbr> </div> <div id="Tao2023" class="col-sm-9"> <div class="title">Collaborative and privacy-preserving retired battery sorting for profitable direct recycling via federated machine learning</div> <div class="author"> Shengyu Tao,¬†Haizhou Liu,¬†Chongbo Sun,¬†Haocheng Ji,¬†Guanjun Ji,¬†Zhiyuan Han, and <span class="more-authors" title="click to view 11 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '11 more authors' ? 'Runhua Gao, Jun Ma, Ruifei Ma, Yuou Chen, Shiyi Fu, Yu Wang, Yaojie Sun, Yu Rong, Xuan Zhang, Guangmin Zhou, Hongbin Sun' : '11 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">11 more authors</span> </div> <div class="periodical"> <em>Nature Communications</em>, Dec 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.nature.com/articles/s41467-023-43883-y.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Unsorted retired batteries with varied cathode materials hinder the adoption of direct recycling due to their cathode-specific nature. The surge in retired batteries necessitates precise sorting for effective direct recycling, but challenges arise from varying operational histories, diverse manufacturers, and data privacy concerns of recycling collaborators (data owners). Here we show, from a unique dataset of 130 lithium-ion batteries spanning 5 cathode materials and 7 manufacturers, a federated machine learning approach can classify these retired batteries without relying on past operational data, safeguarding the data privacy of recycling collaborators. By utilizing the features extracted from the end-of-life charge-discharge cycle, our model exhibits 1% and 3% cathode sorting errors under homogeneous and heterogeneous battery recycling settings respectively, attributed to our innovative Wasserstein-distance voting strategy. Economically, the proposed method underscores the value of precise battery sorting for a prosperous and sustainable recycling industry. This study heralds a new paradigm of using privacy-sensitive data from diverse sources, facilitating collaborative and privacy-respecting decision-making for distributed systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Tao2023</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Collaborative and privacy-preserving retired battery sorting for profitable direct recycling via federated machine learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tao, Shengyu and Liu, Haizhou and Sun, Chongbo and Ji, Haocheng and Ji, Guanjun and Han, Zhiyuan and Gao, Runhua and Ma, Jun and Ma, Ruifei and Chen, Yuou and Fu, Shiyi and Wang, Yu and Sun, Yaojie and Rong, Yu and Zhang, Xuan and Zhou, Guangmin and Sun, Hongbin}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">day</span> <span class="p">=</span> <span class="s">{05}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Nature Communications}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8032}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1038/s41467-023-43883-y}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2041-1723}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1038/s41467-023-43883-y}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">KDD</abbr> </div> <div id="10.1145/3580305.3599475" class="col-sm-9"> <div class="title">Privacy Matters: Vertical Federated Linear Contextual Bandits for Privacy Protected Recommendation</div> <div class="author"> Zeyu Cao,¬†Zhipeng Liang,¬†Bingzhe Wu,¬†Shu Zhang,¬†Hangyu Li,¬†Ouyang Wen, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Yu Rong, Peilin Zhao' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Recent awareness of privacy protection and compliance requirement resulted in a controversial view of recommendation system due to personal data usage. Therefore, privacy-protected recommendation emerges as a novel research direction. In this paper, we first formulate this problem as a vertical federated learning problem, i.e., features are vertically distributed over different departments. We study a contextual bandit learning problem for recommendation in the vertical federated setting. To this end, we carefully design a customized encryption scheme named orthogonal matrix-based mask mechanism (O3M). O3M mechanism, a tailored component for contextual bandits by carefully exploiting their shared structure, can ensure privacy protection while avoiding expensive conventional cryptographic techniques. We further apply the mechanism to two commonly-used bandit algorithms, LinUCB and LinTS, and instantiate two practical protocols for online recommendation. The proposed protocols can perfectly recover the service quality of centralized bandit algorithms while achieving a satisfactory runtime efficiency, which is theoretically proved and analysed in this paper. By conducting extensive experiments on both synthetic and real-world datasets, we show the superiority of the proposed method in terms of privacy protection and recommendation performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3580305.3599475</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Privacy Matters: Vertical Federated Linear Contextual Bandits for Privacy Protected Recommendation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cao, Zeyu and Liang, Zhipeng and Wu, Bingzhe and Zhang, Shu and Li, Hangyu and Wen, Ouyang and Rong, Yu and Zhao, Peilin}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Long Beach, CA, USA}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{KDD '23}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{154‚Äì166}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3580305.3599475}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400701030}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3580305.3599475}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{vertical federated learning, privacy- preserving protocols, linear contextual bandits}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">CIKM</abbr> </div> <div id="10.1145/3583780.3614893" class="col-sm-9"> <div class="title">Geometric Graph Learning for Protein Mutation Effect Prediction</div> <div class="author"> Kangfei Zhao,¬†<em>Yu Rong</em>,¬†Biaobin Jiang,¬†Jianheng Tang,¬†Hengtong Zhang,¬†Jeffrey Xu Yu, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Peilin Zhao' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em>, 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://drive.google.com/file/u/1/d/1iHYjXvsHp_Qgvie9KZ7qx7UHxlvJWFqP/view" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Kangfei/HGIN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/slides/CIKM23-HGIN-paper1727" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Proteins govern a wide range of biological systems. Evaluating the changes in protein properties upon protein mutation is a fundamental application of protein design, where modeling the 3D protein structure is a principal task for AI-driven computational approaches. Existing deep learning (DL) approaches represent the protein structure as a 3D geometric graph and simplify the graph modeling to different degrees, thereby failing to capture the low-level atom patterns and high-level amino acid patterns simultaneously. In addition, limited training samples with ground truth labels and protein structures further restrict the effectiveness of DL approaches. In this paper, we propose a new graph learning framework, Hierarchical Graph Invariant Network (HGIN), a fine-grained and data-efficient graph neural encoder for encoding protein structures and predicting the mutation effect on protein properties. For fine-grained modeling, HGIN hierarchically models the low-level interactions of atoms and the high-level interactions of amino acid residues by Graph Neural Networks. For data efficiency, HGIN preserves the invariant encoding for atom permutation and coordinate transformation, which is an intrinsic inductive bias of property prediction that bypasses data augmentations. We integrate HGIN into a Siamese network to predict the quantitative effect on protein properties upon mutations. Our approach outperforms 9 state-of-the-art approaches on 3 protein datasets. More inspiringly, when predicting the neutralizing ability of human antibodies against COVID-19 mutant viruses, HGIN achieves an absolute improvement of 0.23 regarding the Spearman coefficient.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3583780.3614893</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Geometric Graph Learning for Protein Mutation Effect Prediction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhao, Kangfei and Rong, Yu and Jiang, Biaobin and Tang, Jianheng and Zhang, Hengtong and Yu, Jeffrey Xu and Zhao, Peilin}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 32nd ACM International Conference on Information and Knowledge Management}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Birmingham, United Kingdom}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CIKM '23}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3412‚Äì3422}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3583780.3614893}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400701245}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3583780.3614893}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{graph neural network, geometric graph learning}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> </div> <div id="NEURIPS2023_8e2a75e0" class="col-sm-9"> <div class="title">Equivariant Spatio-Temporal Attentive Graph Networks to Simulate Physical Dynamics</div> <div class="author"> Liming Wu,¬†Zhichao Hou,¬†Jirui Yuan,¬†<em>Yu Rong</em>,¬†and¬†Wenbing Huang</div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em>, 2023 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/8e2a75e0c7b579a6cf176dc0858cde55-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/GLAD-RUC/ESTAG" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/slides/NeurIPS2023-ESTAG.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">NEURIPS2023_8e2a75e0</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Equivariant Spatio-Temporal Attentive Graph Networks to Simulate Physical Dynamics}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Liming and Hou, Zhichao and Yuan, Jirui and Rong, Yu and Huang, Wenbing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{45360--45380}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.neurips.cc/paper_files/paper/2023/file/8e2a75e0c7b579a6cf176dc0858cde55-Paper-Conference.pdf}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Oh, A. and Naumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <h2 id="talks" class="publications">üí¨ Talks</h2> <h2 id="honors-and-awards" class="publications">üéñHonors and Awards</h2> <ul> <li> <strong>2022</strong>, Champion of 2nd Open Catalyst Challenge, NeurIPS</li> <li> <strong>2020</strong>, 10% of High-scoring Reviewers, NeurIPS</li> <li> <strong>2017</strong>, Research Fellowship Scheme, CUHK</li> <li> <strong>2012</strong>, Outstanding Undergraduate Thesis Award, SYSU</li> <li> <strong>2012</strong>, National Undergraduate Scholarship, MoE</li> <li> <strong>2011</strong>, Google Excellence Scholarship, Google</li> </ul> </div> <hr> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="more-info"> <p>555 your office number</p> <p>123 your address street</p> <p>Your City, State 12345</p> </div> </div> <div class="clearfix"> <p>Hi! I am currently the head of Language And Science AI Lab (LASA) of <a href="https://damo.alibaba.com/" rel="external nofollow noopener" target="_blank">DAMO Academy of Alibaba Group</a>. I am generally interested in developing the novel and efficient models with various complex data structures, includeing graphs and sequences to tackle real-world challenges, particularly in the realm of Language and Science.</p> <p>Prior joining DAMO Academy, I served as a principal researcher at <a href="https://ai.tencent.com/" rel="external nofollow noopener" target="_blank">Tencent AI Lab</a> for seven years. I briefly served as a Postdoctoral Research Fellow at The Chinese University of Hong Kong. I received Ph.D degree at <a href="https://www.cuhk.edu.hk/" rel="external nofollow noopener" target="_blank">The Chinese University of Hong Kong</a> in 2016, under the supervision of Professor <a href="https://www1.se.cuhk.edu.hk/~hcheng/" rel="external nofollow noopener" target="_blank">Hong CHENG</a>. Before that I obtained my B.S. degree with honors from <a href="https://www.sysu.edu.cn/" rel="external nofollow noopener" target="_blank">Sun Yat-sen University</a>.</p> <font color="red"> <strong>JOB OPENINGS NOW!!</strong>: I am looking for highly motivated <a href="https://talent-holding.alibaba.com/campus/position-detail?lang=zh&amp;positionId=2041201" rel="external nofollow noopener" target="_blank">full-time positions</a> / <a href="https://talent-holding.alibaba.com/campus/position-detail?lang=zh&amp;positionId=2036809" rel="external nofollow noopener" target="_blank">research interns</a> on large language model and AI for Science. </font> <h2 class="publications"><a href="/news/" style="color: inherit;">üî• What's New </a></h2> <div class="news"> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">May, 2025</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> Tow papers are accepted by ICML 2025! </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Mar, 2025</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> Released a new multilingual language model <a href="https://babel-llm.github.io/babel-llm/" rel="external nofollow noopener" target="_blank">babel</a>, covering the top 25 languages by number of speakers, supports over 90% of the global population. </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Feb, 2025</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> I will serve as Area Chair for KDD 2025. </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Jan, 2025</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> Four papers are accepted by ICLR 2025! <a href="https://openreview.net/forum?id=xJDxVDG3x2" rel="external nofollow noopener" target="_blank"> MolSpectra</a>, <a href="https://openreview.net/forum?id=nYPuSzGE3X" rel="external nofollow noopener" target="_blank">InversionGNN</a>,<a href="https://openreview.net/forum?id=mun3bGqdDM" rel="external nofollow noopener" target="_blank">Atomas</a> and <a href="https://openreview.net/forum?id=YslOW2SO6S" rel="external nofollow noopener" target="_blank">CirT</a>. </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Nov, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> One paper is accepted by ICDE 2025! </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Nov, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> One paper about sustainable battery recycling is published by Nature Communications! Check out this <a href="https://www.nature.com/articles/s41467-024-54454-0" rel="external nofollow noopener" target="_blank">Link</a> </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Nov, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> One paper for the protein desgin is accepted by KDD 2025! Check out our project page: <a href="https://ychaohao.github.io/PAAG/" rel="external nofollow noopener" target="_blank">PAAG</a> </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Aug, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> The campus recruitment of Damo Academy has started, offering <a href="https://talent-holding.alibaba.com/campus/position-list?campusType=freshman&amp;lang=zh" rel="external nofollow noopener" target="_blank">four positions</a> related to AI4Sci. </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Aug, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> I will serve as Area Chair for ICLR 2025. </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Jul, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> Two papers are accepted by CIKM 2024! Check out this <a href="https://dl.acm.org/doi/abs/10.1145/3627673.3679547" rel="external nofollow noopener" target="_blank">GLDM</a> and <a href="https://dl.acm.org/doi/abs/10.1145/3627673.3679529" rel="external nofollow noopener" target="_blank">NLA-MMR</a> </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Jul, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> Move to Hangzhou and join the DAMO Academy, Alibaba Group. </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">May, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> One paper is accepted by KDD 2024! </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">May, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> One paper is accepted by VLDB 2024! </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Mar, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> Our paper <a href="https://www.nature.com/articles/s41592-024-02214-9" rel="external nofollow noopener" target="_blank">scPROTEIN</a> are accepted by Nature Methods! </td> </tr> <tr> <th scope="row" style="padding-top: 0.1rem; padding-bottom: 0.1rem;">Mar, 2024</th> <td style="padding-top: 0.1rem; padding-bottom: 0.1rem;"> A Survey of Geometric Graph Neural Networks is online now! <a href="https://arxiv.org/abs/2403.00485" rel="external nofollow noopener" target="_blank">link</a> </td> </tr> </table> </div> </div> </div> <h2 class="publications">üîç Current Research Topics</h2> <ul> <li>Deep Graph Learning <ul> <li>Foundations of Graph Neural Network</li> </ul> </li> <li>Large Language Models</li> <li>AI for Science <ul> <li>AI for Drug Discovery</li> <li>Physical Dynamic Simulation</li> </ul> </li> </ul> <h2 id="-recent-publications">üìù Recent Publications</h2> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">KDD</abbr> </div> <div id="10.1145/3637528.3671957" class="col-sm-9"> <div class="title">Relaxing Continuous Constraints of Equivariant Graph Neural Networks for Broad Physical Dynamics Learning</div> <div class="author"> Zinan Zheng,¬†Yang Liu,¬†Jia Li,¬†Jianhua Yao,¬†and¬†<em>Yu Rong</em> </div> <div class="periodical"> <em>In Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/Relaxing%20Continuous%20Constraints%20of%20Equivariant%20Graph%20Neural%20Networks%20for%20Broad%20Physical%20Dynamics%20Learning.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/compasszzn/DEGNN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Incorporating Euclidean symmetries (e.g. rotation equivariance) as inductive biases into graph neural networks has improved their generalization ability and data efficiency in unbounded physical dynamics modeling. However, in various scientific and engineering applications, the symmetries of dynamics are frequently discrete due to the boundary conditions. Thus, existing GNNs either over-look necessary symmetry, resulting in suboptimal representation ability, or impose excessive equivariance, which fails to generalize to unobserved symmetric dynamics. In this work, we propose a general Discrete Equivariant Graph Neural Network (DEGNN) that guarantees equivariance to a given discrete point group. Specifically, we show that such discrete equivariant message passing could be constructed by transforming geometric features into permutation-invariant embeddings. Through relaxing continuous equivariant constraints, DEGNN can employ more geometric feature combinations to approximate unobserved physical object interaction functions. Two implementation approaches of DEGNN are proposed based on ranking or pooling permutation-invariant functions. We apply DEGNN to various physical dynamics, ranging from particle, molecular, crowd to vehicle dynamics. In twenty scenarios, DEGNN significantly outperforms existing state-of-the-art approaches. Moreover, we show that DEGNN is data efficient, learning with less data, and can generalize across scenarios such as unobserved orientation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3637528.3671957</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Relaxing Continuous Constraints of Equivariant Graph Neural Networks for Broad Physical Dynamics Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zheng, Zinan and Liu, Yang and Li, Jia and Yao, Jianhua and Rong, Yu}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Barcelona, Spain}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{KDD '24}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4548‚Äì4558}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3637528.3671957}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400704901}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3637528.3671957}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{equivariant graph neural network, physical dynamics}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> </div> <div id="liu2024segno" class="col-sm-9"> <div class="title">SEGNO: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases</div> <div class="author"> Yang Liu,¬†Jiashun Cheng,¬†Haihong Zhao,¬†Tingyang Xu,¬†Peilin Zhao,¬†Fugee Tsung, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Jia Li, Yu Rong' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">2 more authors</span> </div> <div class="periodical"> <em>In The Twelfth International Conference on Learning Representations</em>, 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/pdf?id=3oTPsORaDH" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/yliukj/SEGNO" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">liu2024segno</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{SEGNO}: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liu, Yang and Cheng, Jiashun and Zhao, Haihong and Xu, Tingyang and Zhao, Peilin and Tsung, Fugee and Li, Jia and Rong, Yu}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The Twelfth International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=3oTPsORaDH}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">VLDB</abbr> </div> <div id="10.14778/3675034.3675048" class="col-sm-9"> <div class="title">Inductive Attributed Community Search: To Learn Communities Across Graphs</div> <div class="author"> Shuheng Fang,¬†Kangfei Zhao,¬†<em>Yu Rong</em>,¬†Zhixun Li,¬†and¬†Jeffrey Xu Yu</div> <div class="periodical"> <em>Proc. VLDB Endow.</em>, Aug 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/FangShuheng/IACS" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/slides/VLDB24-IACS.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Attributed community search (ACS) aims to identify subgraphs satisfying both structure cohesiveness and attribute homogeneity in attributed graphs, for a given query that contains query nodes and query attributes. Previously, algorithmic approaches deal with ACS in a two-stage paradigm, which suffer from structural inflexibility and attribute irrelevance. To overcome this problem, recently, learning-based approaches have been proposed to learn both structures and attributes simultaneously as a one-stage paradigm. However, these approaches train a transductive model which assumes the graph to infer unseen queries is as same as the graph used for training. That limits the generalization and adaptation of these approaches to different heterogeneous graphs.In this paper, we propose a new framework, Inductive Attributed Community Search, IACS, by inductive learning, which can be used to infer new queries for different communities/graphs. Specifically, IACS employs an encoder-decoder neural architecture to handle an ACS task at a time, where a task consists of a graph with only a few queries and corresponding ground-truth. We design a three-phase workflow, "training-adaptation-inference", which learns a shared model to absorb and induce prior effective common knowledge about ACS across different tasks. And the shared model can swiftly adapt to a new task with small number of ground-truth. We conduct substantial experiments in 7 real-world datasets to verify the effectiveness of IACS for CS/ACS. Our approach IACS achieves 28.97% and 25.60% improvements in F1-score on average in CS and ACS, respectively.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10.14778/3675034.3675048</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Inductive Attributed Community Search: To Learn Communities Across Graphs}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fang, Shuheng and Zhao, Kangfei and Rong, Yu and Li, Zhixun and Yu, Jeffrey Xu}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">aug</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Proc. VLDB Endow.}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{VLDB Endowment}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2576‚Äì2589}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.14778/3675034.3675048}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2150-8097}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.14778/3675034.3675048}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{June 2024}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> </div> <div id="li2024neural" class="col-sm-9"> <div class="title">Neural Atoms: Propagating Long-range Interaction in Molecular Graphs through Efficient Communication Channel</div> <div class="author"> Xuan Li,¬†Zhanke Zhou,¬†Jiangchao Yao,¬†<em>Yu Rong</em>,¬†Lu Zhang,¬†and¬†Bo Han</div> <div class="periodical"> <em>In The Twelfth International Conference on Learning Representations</em>, 2024 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://openreview.net/pdf?id=CUfSCwcgqm" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/tmlr-group/NeuralAtom" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">li2024neural</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Neural Atoms: Propagating Long-range Interaction in Molecular Graphs through Efficient Communication Channel}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Xuan and Zhou, Zhanke and Yao, Jiangchao and Rong, Yu and Zhang, Lu and Han, Bo}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{The Twelfth International Conference on Learning Representations}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=CUfSCwcgqm}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">Nature Methods</abbr> </div> <div id="Li2024" class="col-sm-9"> <div class="title">scPROTEIN: a versatile deep graph contrastive learning framework for single-cell proteomics embedding</div> <div class="author"> Wei Li,¬†Fan Yang,¬†Fang Wang,¬†<em>Yu Rong</em>,¬†Linjing Liu,¬†Bingzhe Wu, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Han Zhang, Jianhua Yao' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">2 more authors</span> </div> <div class="periodical"> <em>Nature Methods</em>, Apr 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/TencentAILabHealthcare/scPROTEIN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/slides/NM-scPROTEIN_pub.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Single-cell proteomics sequencing technology sheds light on protein‚Äìprotein interactions, posttranslational modifications and proteoform dynamics in the cell. However, the uncertainty estimation for peptide quantification, data missingness, batch effects and high noise hinder the analysis of single-cell proteomic data. It is important to solve this set of tangled problems together, but the existing methods tailored for single-cell transcriptomes cannot fully address this task. Here we propose a versatile framework designed for single-cell proteomics data analysis called scPROTEIN, which consists of peptide uncertainty estimation based on a multitask heteroscedastic regression model and cell embedding generation based on graph contrastive learning. scPROTEIN can estimate the uncertainty of peptide quantification, denoise protein data, remove batch effects and encode single-cell proteomic-specific embeddings in a unified framework. We demonstrate that scPROTEIN is efficient for cell clustering, batch correction, cell type annotation, clinical analysis and spatially resolved proteomic data exploration.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Li2024</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{scPROTEIN: a versatile deep graph contrastive learning framework for single-cell proteomics embedding}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Li, Wei and Yang, Fan and Wang, Fang and Rong, Yu and Liu, Linjing and Wu, Bingzhe and Zhang, Han and Yao, Jianhua}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">day</span> <span class="p">=</span> <span class="s">{01}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Nature Methods}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{21}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{623--634}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1038/s41592-024-02214-9}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1548-7105}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1038/s41592-024-02214-9}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">CIKM</abbr> </div> <div id="DBLP:conf/cikm/TanRZBXH0M24" class="col-sm-9"> <div class="title">Natural Language-Assisted Multi-modal Medication Recommendation</div> <div class="author"> Jie Tan,¬†<em>Yu Rong</em>,¬†Kangfei Zhao,¬†Tian Bian,¬†Tingyang Xu,¬†Junzhou Huang, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Hong Cheng, Helen Meng' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 33rd ACM International Conference on Information and Knowledge Management, CIKM 2024, Boise, ID, USA, October 21-25, 2024</em>, 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://nlammr.github.io/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://arxiv.org/pdf/2501.07166v1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/jtan1102/NLA-MMR_CIKM_2024" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Combinatorial medication recommendation (CMR) is a fundamental task of healthcare, which offers opportunities for clinical physicians to provide more precise prescriptions for patients with intricate health conditions, particularly in the scenarios of long-term medical care. Previous research efforts have sought to extract meaningful information from electronic health records (EHRs) to facilitate combinatorial medication recommendations. Existing learning-based approaches further consider the chemical structures of medications, but ignore the textual medication descriptions in which the functionalities are clearly described. Furthermore, the textual knowledge derived from the EHRs of patients remains largely underutilized. To address these issues, we introduce the Natural Language-Assisted Multi-modal Medication Recommendation (NLAMMR), a multi-modal alignment framework designed to learn knowledge from the patient view and medication view jointly. Specifically, NLAMMR formulates CMR as an alignment problem from patient and medication modalities. In this vein, we employ pretrained language models (PLMs) to extract in-domain knowledge regarding patients and medications, serving as the foundational representation for both modalities. In the medication modality, we exploit both chemical structures and textual descriptions to create medication representations. In the patient modality, we generate the patient representations based on textual descriptions of diagnosis, procedure, and symptom. Extensive experiments conducted on three publicly accessible datasets demonstrate that NLAMMR achieves new state-of-the-art performance, with a notable average improvement of 4.72% in Jaccard score.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/cikm/TanRZBXH0M24</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tan, Jie and Rong, Yu and Zhao, Kangfei and Bian, Tian and Xu, Tingyang and Huang, Junzhou and Cheng, Hong and Meng, Helen}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Serra, Edoardo and Spezzano, Francesca}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Natural Language-Assisted Multi-modal Medication Recommendation}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 33rd {ACM} International Conference on Information
                          and Knowledge Management, {CIKM} 2024, Boise, ID, USA, October 21-25,
                          2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2200--2209}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{{ACM}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3627673.3679529}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3627673.3679529}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Sat, 30 Nov 2024 21:10:26 +0100}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/conf/cikm/TanRZBXH0M24.bib}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">Nature Comm.</abbr> </div> <div id="Tao2023" class="col-sm-9"> <div class="title">Collaborative and privacy-preserving retired battery sorting for profitable direct recycling via federated machine learning</div> <div class="author"> Shengyu Tao,¬†Haizhou Liu,¬†Chongbo Sun,¬†Haocheng Ji,¬†Guanjun Ji,¬†Zhiyuan Han, and <span class="more-authors" title="click to view 11 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '11 more authors' ? 'Runhua Gao, Jun Ma, Ruifei Ma, Yuou Chen, Shiyi Fu, Yu Wang, Yaojie Sun, Yu Rong, Xuan Zhang, Guangmin Zhou, Hongbin Sun' : '11 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">11 more authors</span> </div> <div class="periodical"> <em>Nature Communications</em>, Dec 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.nature.com/articles/s41467-023-43883-y.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Unsorted retired batteries with varied cathode materials hinder the adoption of direct recycling due to their cathode-specific nature. The surge in retired batteries necessitates precise sorting for effective direct recycling, but challenges arise from varying operational histories, diverse manufacturers, and data privacy concerns of recycling collaborators (data owners). Here we show, from a unique dataset of 130 lithium-ion batteries spanning 5 cathode materials and 7 manufacturers, a federated machine learning approach can classify these retired batteries without relying on past operational data, safeguarding the data privacy of recycling collaborators. By utilizing the features extracted from the end-of-life charge-discharge cycle, our model exhibits 1% and 3% cathode sorting errors under homogeneous and heterogeneous battery recycling settings respectively, attributed to our innovative Wasserstein-distance voting strategy. Economically, the proposed method underscores the value of precise battery sorting for a prosperous and sustainable recycling industry. This study heralds a new paradigm of using privacy-sensitive data from diverse sources, facilitating collaborative and privacy-respecting decision-making for distributed systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Tao2023</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Collaborative and privacy-preserving retired battery sorting for profitable direct recycling via federated machine learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tao, Shengyu and Liu, Haizhou and Sun, Chongbo and Ji, Haocheng and Ji, Guanjun and Han, Zhiyuan and Gao, Runhua and Ma, Jun and Ma, Ruifei and Chen, Yuou and Fu, Shiyi and Wang, Yu and Sun, Yaojie and Rong, Yu and Zhang, Xuan and Zhou, Guangmin and Sun, Hongbin}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">day</span> <span class="p">=</span> <span class="s">{05}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Nature Communications}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8032}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1038/s41467-023-43883-y}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2041-1723}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1038/s41467-023-43883-y}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">KDD</abbr> </div> <div id="10.1145/3580305.3599475" class="col-sm-9"> <div class="title">Privacy Matters: Vertical Federated Linear Contextual Bandits for Privacy Protected Recommendation</div> <div class="author"> Zeyu Cao,¬†Zhipeng Liang,¬†Bingzhe Wu,¬†Shu Zhang,¬†Hangyu Li,¬†Ouyang Wen, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Yu Rong, Peilin Zhao' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>, 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Recent awareness of privacy protection and compliance requirement resulted in a controversial view of recommendation system due to personal data usage. Therefore, privacy-protected recommendation emerges as a novel research direction. In this paper, we first formulate this problem as a vertical federated learning problem, i.e., features are vertically distributed over different departments. We study a contextual bandit learning problem for recommendation in the vertical federated setting. To this end, we carefully design a customized encryption scheme named orthogonal matrix-based mask mechanism (O3M). O3M mechanism, a tailored component for contextual bandits by carefully exploiting their shared structure, can ensure privacy protection while avoiding expensive conventional cryptographic techniques. We further apply the mechanism to two commonly-used bandit algorithms, LinUCB and LinTS, and instantiate two practical protocols for online recommendation. The proposed protocols can perfectly recover the service quality of centralized bandit algorithms while achieving a satisfactory runtime efficiency, which is theoretically proved and analysed in this paper. By conducting extensive experiments on both synthetic and real-world datasets, we show the superiority of the proposed method in terms of privacy protection and recommendation performance.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3580305.3599475</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Privacy Matters: Vertical Federated Linear Contextual Bandits for Privacy Protected Recommendation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cao, Zeyu and Liang, Zhipeng and Wu, Bingzhe and Zhang, Shu and Li, Hangyu and Wen, Ouyang and Rong, Yu and Zhao, Peilin}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Long Beach, CA, USA}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{KDD '23}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{154‚Äì166}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3580305.3599475}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400701030}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3580305.3599475}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{vertical federated learning, privacy- preserving protocols, linear contextual bandits}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">CIKM</abbr> </div> <div id="10.1145/3583780.3614893" class="col-sm-9"> <div class="title">Geometric Graph Learning for Protein Mutation Effect Prediction</div> <div class="author"> Kangfei Zhao,¬†<em>Yu Rong</em>,¬†Biaobin Jiang,¬†Jianheng Tang,¬†Hengtong Zhang,¬†Jeffrey Xu Yu, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Peilin Zhao' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '5'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management</em>, 2023 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://drive.google.com/file/u/1/d/1iHYjXvsHp_Qgvie9KZ7qx7UHxlvJWFqP/view" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Kangfei/HGIN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/slides/CIKM23-HGIN-paper1727" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> </div> <div class="abstract hidden"> <p>Proteins govern a wide range of biological systems. Evaluating the changes in protein properties upon protein mutation is a fundamental application of protein design, where modeling the 3D protein structure is a principal task for AI-driven computational approaches. Existing deep learning (DL) approaches represent the protein structure as a 3D geometric graph and simplify the graph modeling to different degrees, thereby failing to capture the low-level atom patterns and high-level amino acid patterns simultaneously. In addition, limited training samples with ground truth labels and protein structures further restrict the effectiveness of DL approaches. In this paper, we propose a new graph learning framework, Hierarchical Graph Invariant Network (HGIN), a fine-grained and data-efficient graph neural encoder for encoding protein structures and predicting the mutation effect on protein properties. For fine-grained modeling, HGIN hierarchically models the low-level interactions of atoms and the high-level interactions of amino acid residues by Graph Neural Networks. For data efficiency, HGIN preserves the invariant encoding for atom permutation and coordinate transformation, which is an intrinsic inductive bias of property prediction that bypasses data augmentations. We integrate HGIN into a Siamese network to predict the quantitative effect on protein properties upon mutations. Our approach outperforms 9 state-of-the-art approaches on 3 protein datasets. More inspiringly, when predicting the neutralizing ability of human antibodies against COVID-19 mutant viruses, HGIN achieves an absolute improvement of 0.23 regarding the Spearman coefficient.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3583780.3614893</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Geometric Graph Learning for Protein Mutation Effect Prediction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhao, Kangfei and Rong, Yu and Jiang, Biaobin and Tang, Jianheng and Zhang, Hengtong and Yu, Jeffrey Xu and Zhao, Peilin}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 32nd ACM International Conference on Information and Knowledge Management}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Birmingham, United Kingdom}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CIKM '23}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3412‚Äì3422}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3583780.3614893}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400701245}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3583780.3614893}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{graph neural network, geometric graph learning}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> </div> <div id="NEURIPS2023_8e2a75e0" class="col-sm-9"> <div class="title">Equivariant Spatio-Temporal Attentive Graph Networks to Simulate Physical Dynamics</div> <div class="author"> Liming Wu,¬†Zhichao Hou,¬†Jirui Yuan,¬†<em>Yu Rong</em>,¬†and¬†Wenbing Huang</div> <div class="periodical"> <em>In Advances in Neural Information Processing Systems</em>, 2023 </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/8e2a75e0c7b579a6cf176dc0858cde55-Paper-Conference.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/GLAD-RUC/ESTAG" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/slides/NeurIPS2023-ESTAG.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> <div class="badges"> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">NEURIPS2023_8e2a75e0</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Equivariant Spatio-Temporal Attentive Graph Networks to Simulate Physical Dynamics}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Liming and Hou, Zhichao and Yuan, Jirui and Rong, Yu and Huang, Wenbing}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Advances in Neural Information Processing Systems}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Curran Associates, Inc.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{36}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{45360--45380}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://proceedings.neurips.cc/paper_files/paper/2023/file/8e2a75e0c7b579a6cf176dc0858cde55-Paper-Conference.pdf}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Oh, A. and Naumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <h2 id="talks" class="publications">üí¨ Talks</h2> <h2 id="honors-and-awards" class="publications">üéñHonors and Awards</h2> <ul> <li> <strong>2022</strong>, Champion of 2nd Open Catalyst Challenge, NeurIPS</li> <li> <strong>2020</strong>, 10% of High-scoring Reviewers, NeurIPS</li> <li> <strong>2017</strong>, Research Fellowship Scheme, CUHK</li> <li> <strong>2012</strong>, Outstanding Undergraduate Thesis Award, SYSU</li> <li> <strong>2012</strong>, National Undergraduate Scholarship, MoE</li> <li> <strong>2011</strong>, Google Excellence Scholarship, Google</li> </ul> </div> </article> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> ¬© Copyright 2025 Yu Rong (Ëç£Èí∞). Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: May 02, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id="></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>